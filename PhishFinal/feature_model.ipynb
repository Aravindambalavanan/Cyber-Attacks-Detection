{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from url_preprocessing.url_feature_extraction import FeatureExtractor\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    data = data.sample(frac=1).reset_index(drop=True)\n",
    "    data = data.drop(['Index'], axis=1)\n",
    "    X = data.drop([\"class\"], axis=1)\n",
    "    y = data[\"class\"]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size=0.2, random_state=42):\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    \"Logistic Regression\": {'solver': ['liblinear', 'saga'], 'C': [1, 10, 100], 'penalty': ['l1','l2']},\n",
    "    \"Support Vector Machine\": {'C': [1, 10, 100], 'gamma': ['scale', 'auto', 0.1], 'kernel': ['linear', 'rbf', 'poly']},\n",
    "    \"Random Forest\": {'n_estimators': [200, 400, 600], 'max_depth': [None, 20, 50], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]},\n",
    "    \"LightGBM\": {'learning_rate': [0.05, 0.1], 'num_leaves': [20, 30], 'max_depth': [5, 7], 'min_child_samples': [10, 20], 'subsample': [0.8, 0.9], 'colsample_bytree': [0.8, 0.9], 'reg_alpha': [0.0, 0.1], 'reg_lambda': [0.0, 0.1], 'verbose': [-1]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_results(ML_Model, accuracy_train, accuracy_test, f1_score_train, f1_score_test, recall_train, recall_test, precision_train, precision_test):\n",
    "    results = {\"ML Model\": ML_Model, \"Accuracy (Train)\": accuracy_train, \"Accuracy (Test)\": accuracy_test, \"F1 Score (Train)\": f1_score_train, \"F1 Score (Test)\": f1_score_test, \"Recall (Train)\": recall_train, \"Recall (Test)\": recall_test, \"Precision (Train)\": precision_train, \"Precision (Test)\": precision_test}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    best_classifier = model.best_estimator_\n",
    "    print(f\"GridSearchCV results for {name}:\")\n",
    "    print(\"Best parameters found:\")\n",
    "    print(best_classifier.get_params())\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    acc_train = metrics.accuracy_score(y_train, y_train_pred)\n",
    "    acc_test = metrics.accuracy_score(y_test, y_test_pred)\n",
    "    f1_train = metrics.f1_score(y_train, y_train_pred)\n",
    "    f1_test = metrics.f1_score(y_test, y_test_pred)\n",
    "    recall_train = metrics.recall_score(y_train, y_train_pred)\n",
    "    recall_test = metrics.recall_score(y_test, y_test_pred)\n",
    "    precision_train = metrics.precision_score(y_train, y_train_pred)\n",
    "    precision_test = metrics.precision_score(y_test, y_test_pred)\n",
    "    return acc_train, acc_test, f1_train, f1_test, recall_train, recall_test, precision_train, precision_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_results(ML_Model, accuracy_train, accuracy_test, f1_score_train, f1_score_test, recall_train, recall_test, precision_train, precision_test):\n",
    "    results = {\"ML Model\": ML_Model, \"Accuracy (Train)\": accuracy_train, \"Accuracy (Test)\": accuracy_test, \"F1 Score (Train)\": f1_score_train, \"F1 Score (Test)\": f1_score_test, \"Recall (Train)\": recall_train, \"Recall (Test)\": recall_test, \"Precision (Train)\": precision_train, \"Precision (Test)\": precision_test}\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_data(X_train, y_train):\n",
    "    \n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    return X_train_resampled, y_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV results for Logistic Regression:\n",
      "Best parameters found:\n",
      "{'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Phishing       0.91      0.91      0.91       972\n",
      "  Legitimate       0.93      0.93      0.93      1239\n",
      "\n",
      "    accuracy                           0.92      2211\n",
      "   macro avg       0.92      0.92      0.92      2211\n",
      "weighted avg       0.92      0.92      0.92      2211\n",
      "\n",
      "GridSearchCV results for Support Vector Machine:\n",
      "Best parameters found:\n",
      "{'C': 10, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 0.1, 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "Classification Report for Support Vector Machine:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Phishing       0.97      0.96      0.96       972\n",
      "  Legitimate       0.97      0.98      0.97      1239\n",
      "\n",
      "    accuracy                           0.97      2211\n",
      "   macro avg       0.97      0.97      0.97      2211\n",
      "weighted avg       0.97      0.97      0.97      2211\n",
      "\n",
      "GridSearchCV results for Random Forest:\n",
      "Best parameters found:\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 20, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Phishing       0.97      0.96      0.97       972\n",
      "  Legitimate       0.97      0.98      0.97      1239\n",
      "\n",
      "    accuracy                           0.97      2211\n",
      "   macro avg       0.97      0.97      0.97      2211\n",
      "weighted avg       0.97      0.97      0.97      2211\n",
      "\n",
      "GridSearchCV results for LightGBM:\n",
      "Best parameters found:\n",
      "{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 7, 'min_child_samples': 10, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': None, 'num_leaves': 30, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.1, 'subsample': 0.8, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'verbose': -1}\n",
      "Classification Report for LightGBM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Phishing       0.96      0.95      0.96       972\n",
      "  Legitimate       0.96      0.97      0.96      1239\n",
      "\n",
      "    accuracy                           0.96      2211\n",
      "   macro avg       0.96      0.96      0.96      2211\n",
      "weighted avg       0.96      0.96      0.96      2211\n",
      "\n",
      "Best performing model saved as 'feature_model.joblib'.\n",
      "The best performing model is: Random Forest, with f1-score: 0.9734939759036144\n",
      "                 ML Model  Accuracy (Train)  Accuracy (Test)  \\\n",
      "0           Random Forest          0.991155         0.970149   \n",
      "1  Support Vector Machine          0.985462         0.967888   \n",
      "2                LightGBM          0.977023         0.960651   \n",
      "3     Logistic Regression          0.930155         0.920398   \n",
      "\n",
      "   F1 Score (Train)  F1 Score (Test)  Recall (Train)  Recall (Test)  \\\n",
      "0          0.991168         0.973494        0.992680       0.978208   \n",
      "1          0.985510         0.971474        0.988817       0.975787   \n",
      "2          0.977037         0.964962        0.977633       0.966909   \n",
      "3          0.930753         0.928745        0.938796       0.925747   \n",
      "\n",
      "   Precision (Train)  Precision (Test)  \n",
      "0           0.989661          0.968825  \n",
      "1           0.982226          0.967200  \n",
      "2           0.976442          0.963023  \n",
      "3           0.922846          0.931763  \n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    X, y = load_data(\"data/feature_model_data.csv\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "\n",
    "    X_train, y_train = upsample_data(X_train, y_train)\n",
    "\n",
    "    models = {\n",
    "        \"Logistic Regression\": GridSearchCV(LogisticRegression(), param_grids[\"Logistic Regression\"], cv=5, scoring='f1'),\n",
    "        \"Support Vector Machine\": GridSearchCV(SVC(), param_grids[\"Support Vector Machine\"], cv=5, n_jobs=-1, scoring='f1'),\n",
    "        \"Random Forest\": GridSearchCV(RandomForestClassifier(), param_grids[\"Random Forest\"], cv=5, n_jobs=-1, scoring='f1'),\n",
    "        \"LightGBM\": GridSearchCV(LGBMClassifier(), param_grids[\"LightGBM\"], cv=5, scoring='f1')\n",
    "    }\n",
    "\n",
    "    best_model = None\n",
    "    best_f1_score = 0\n",
    "    best_model_name = \"\"\n",
    "\n",
    "    results = []\n",
    "    for name, model in models.items():\n",
    "        acc_train, acc_test, f1_train, f1_test, recall_train, recall_test, precision_train, precision_test = train_evaluate_model(name, model, X_train, X_test, y_train, y_test)\n",
    "        if f1_test > best_f1_score:\n",
    "            best_f1_score = f1_test\n",
    "            best_model = model\n",
    "            best_model_name = name\n",
    "        results.append(store_results(name, acc_train, acc_test, f1_train, f1_test, recall_train, recall_test, precision_train, precision_test))\n",
    "\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        print(f\"Classification Report for {name}:\")\n",
    "        print(metrics.classification_report(y_test, y_test_pred, target_names=('Phishing', 'Legitimate')))\n",
    "\n",
    "    if best_model is not None:\n",
    "        ml_pipeline = Pipeline([\n",
    "            ('feature_extraction', FeatureExtractor()),\n",
    "            ('model', best_model)\n",
    "        ])\n",
    "        joblib.dump(ml_pipeline, 'feature_model.joblib')\n",
    "        print(\"Best performing model saved as 'feature_model.joblib'.\")\n",
    "        print(f\"The best performing model is: {best_model_name}, with f1-score: {best_f1_score}\")\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    sorted_results = results_df.sort_values(by=['Accuracy (Test)', 'F1 Score (Test)'], ascending=False).reset_index(drop=True)\n",
    "    print(sorted_results)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
